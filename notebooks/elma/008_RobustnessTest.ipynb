{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bad358f-f79d-408f-ac09-210360508ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE THRESHOLD ROBUSTNESS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Starting from adjacency matrices...\n",
      "Thresholds: OR > 1.5 (Baseline), OR > 2.0 (Strict)\n",
      "\n",
      "Step 1: Loading data...\n",
      "  ✓ Loaded 1080 ICD codes\n",
      "  ✓ Loaded prevalence data\n",
      "  ✓ Loaded mortality data\n",
      "\n",
      "Available data:\n",
      "  Female: Age groups [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  Male: Age groups [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "Step 2: Computing critical nodes/edges for each threshold...\n",
      "\n",
      "Processing: OR > 1.5 (Baseline)\n",
      "--------------------------------------------------------------------------------\n",
      "  Female age 1 (0-9)... ✓\n",
      "  Female age 2 (10-19)... ✓\n",
      "  Female age 3 (20-29)... ✓\n",
      "  Female age 4 (30-39)... ✓\n",
      "  Female age 5 (40-49)... ✓\n",
      "  Female age 6 (50-59)... ✓\n",
      "  Female age 7 (60-69)... ✓\n",
      "  Female age 8 (70-79)... ✓\n",
      "  Male age 1 (0-9)... ✓\n",
      "  Male age 2 (10-19)... ✓\n",
      "  Male age 3 (20-29)... ✓\n",
      "  Male age 4 (30-39)... ✓\n",
      "  Male age 5 (40-49)... ✓\n",
      "  Male age 6 (50-59)... ✓\n",
      "  Male age 7 (60-69)... ✓\n",
      "  Male age 8 (70-79)... ✓\n",
      "  ✓ Outliers: 785\n",
      "  ✓ Sinks: 432\n",
      "  ✓ Bridges: 115\n",
      "\n",
      "Processing: OR > 2.0 (Strict)\n",
      "--------------------------------------------------------------------------------\n",
      "  Female age 1 (0-9)... ✓\n",
      "  Female age 2 (10-19)... ✓\n",
      "  Female age 3 (20-29)... ✓\n",
      "  Female age 4 (30-39)... ✓\n",
      "  Female age 5 (40-49)... ✓\n",
      "  Female age 6 (50-59)... ✓\n",
      "  Female age 7 (60-69)... ✓\n",
      "  Female age 8 (70-79)... ✓\n",
      "  Male age 1 (0-9)... ✓\n",
      "  Male age 2 (10-19)... ✓\n",
      "  Male age 3 (20-29)... ✓\n",
      "  Male age 4 (30-39)... ✓\n",
      "  Male age 5 (40-49)... ✓\n",
      "  Male age 6 (50-59)... ✓\n",
      "  Male age 7 (60-69)... ✓\n",
      "  Male age 8 (70-79)... ✓\n",
      "  ✓ Outliers: 753\n",
      "  ✓ Sinks: 430\n",
      "  ✓ Bridges: 93\n",
      "\n",
      "Step 3: Computing overlap statistics...\n",
      "\n",
      "OR > 1.5 vs OR > 2.0:\n",
      "  Outliers: J=0.918, Common=736\n",
      "  Sinks:    J=0.611, Common=327\n",
      "  Bridges:  J=0.529, Common=72\n",
      "\n",
      "Step 4: Saving results...\n",
      "\n",
      "  ✓ Saved: threshold_robustness_summary.csv\n",
      "  ✓ Saved: threshold_robustness_overlap_statistics.csv\n",
      "  ✓ Saved: threshold_or_1.5_outliers.csv\n",
      "  ✓ Saved: threshold_or_1.5_sinks.csv\n",
      "  ✓ Saved: threshold_or_1.5_bridges.csv\n",
      "  ✓ Saved: threshold_or_2.0_outliers.csv\n",
      "  ✓ Saved: threshold_or_2.0_sinks.csv\n",
      "  ✓ Saved: threshold_or_2.0_bridges.csv\n",
      "\n",
      "Step 5: Creating visualizations...\n",
      "\n",
      "  ✓ Saved: threshold_comparison_bars.png\n",
      "  ✓ Saved: threshold_jaccard_indices.png\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "          Condition  OR_Threshold  Outliers  Sinks  Bridges\n",
      "OR > 1.5 (Baseline)           1.5       785    432      115\n",
      "  OR > 2.0 (Strict)           2.0       753    430       93\n",
      "\n",
      "Average Jaccard Indices:\n",
      "  Outliers: 0.918\n",
      "  Sinks:    0.611\n",
      "  Bridges:  0.529\n",
      "  Overall:  0.686 - GOOD\n",
      "\n",
      "Output files:\n",
      "  CSV files: outputs/threshold_*.csv\n",
      "  Figures:   outputs/threshold_robustness_figures/*.png\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "COMPLETE THRESHOLD ROBUSTNESS ANALYSIS\n",
    "======================================\n",
    "\n",
    "This script performs a complete threshold robustness test starting from\n",
    "adjacency matrices and produces all results and visualizations.\n",
    "\n",
    "INPUT:\n",
    "  - Adjacency matrices (Adj_Matrix_*.csv) containing odds ratios\n",
    "  - ICD code mappings (ICD10_Diagnoses_All.csv)\n",
    "  - Prevalence data (Prevalence_Sex_Age_Year_ICD.csv)\n",
    "  - Mortality data (mortality_diag_Female.csv, mortality_diag_Male.csv)\n",
    "\n",
    "OUTPUT:\n",
    "  - CSV files with results for each threshold\n",
    "  - Summary statistics and overlap analysis\n",
    "  - Publication-ready visualizations\n",
    "\n",
    "USAGE:\n",
    "  python threshold_robustness_complete.py\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "DATA_DIR = Path('Data')\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "FIG_DIR = OUTPUT_DIR / 'threshold_robustness_figures'\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Age group mapping\n",
    "AGE_MAP = {1: '0-9', 2: '10-19', 3: '20-29', 4: '30-39',\n",
    "           5: '40-49', 6: '50-59', 7: '60-69', 8: '70-79'}\n",
    "\n",
    "# OR thresholds to test\n",
    "THRESHOLDS = {\n",
    "    'or_1.5': {'name': 'OR > 1.5 (Baseline)', 'value': 1.5},\n",
    "    'or_2.0': {'name': 'OR > 2.0 (Strict)', 'value': 2.0}\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE THRESHOLD ROBUSTNESS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Starting from adjacency matrices...\")\n",
    "print(f\"Thresholds: {', '.join([t['name'] for t in THRESHOLDS.values()])}\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 1: Loading data...\")\n",
    "\n",
    "def load_prevalence_data():\n",
    "    \"\"\"Load ICD codes and prevalence data\"\"\"\n",
    "    icd_df = pd.read_csv(DATA_DIR / 'ICD10_Diagnoses_All.csv')\n",
    "    prev_df = pd.read_csv(DATA_DIR / 'Prevalence_Sex_Age_Year_ICD.csv')\n",
    "    return icd_df, prev_df\n",
    "\n",
    "def load_mortality_data():\n",
    "    \"\"\"Load mortality data from separate male/female files\"\"\"\n",
    "    dfs = []\n",
    "    age_mapping = {1: '0-9', 2: '10-19', 3: '20-29', 4: '30-39',\n",
    "                   5: '40-49', 6: '50-59', 7: '60-69', 8: '70-79'}\n",
    "    \n",
    "    for gender, filepath in [('Female', 'mortality_diag_Female.csv'), \n",
    "                             ('Male', 'mortality_diag_Male.csv')]:\n",
    "        file = DATA_DIR / filepath\n",
    "        if file.exists():\n",
    "            df = pd.read_csv(file)\n",
    "            df['sex'] = gender\n",
    "            if 'age_10' in df.columns:\n",
    "                df['Age_Group'] = df['age_10'].map(age_mapping)\n",
    "            dfs.append(df)\n",
    "    \n",
    "    if dfs:\n",
    "        mort_df = pd.concat(dfs, ignore_index=True)\n",
    "        if 'mortality' in mort_df.columns:\n",
    "            mort_df['mortality'] = pd.to_numeric(mort_df['mortality'], errors='coerce').fillna(0)\n",
    "        return mort_df\n",
    "    return None\n",
    "\n",
    "icd_df, prev_df = load_prevalence_data()\n",
    "mort_df = load_mortality_data()\n",
    "\n",
    "print(f\"  ✓ Loaded {len(icd_df)} ICD codes\")\n",
    "print(f\"  ✓ Loaded prevalence data\")\n",
    "print(f\"  ✓ Loaded mortality data\")\n",
    "print()\n",
    "\n",
    "# Check available age groups\n",
    "available_age_groups = {}\n",
    "for gender in ['Female', 'Male']:\n",
    "    available_age_groups[gender] = []\n",
    "    for age_group in range(1, 9):\n",
    "        adj_path = DATA_DIR / f'Adj_Matrix_{gender}_ICD_age_{age_group}.csv'\n",
    "        if adj_path.exists():\n",
    "            available_age_groups[gender].append(age_group)\n",
    "\n",
    "print(\"Available data:\")\n",
    "for gender in ['Female', 'Male']:\n",
    "    print(f\"  {gender}: Age groups {available_age_groups[gender]}\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DEFINE ANALYSIS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_adjacency_matrix(gender: str, age_group: int, or_threshold: float) -> np.ndarray:\n",
    "    \"\"\"Load adjacency matrix and apply OR threshold\"\"\"\n",
    "    adj_path = DATA_DIR / f'Adj_Matrix_{gender}_ICD_age_{age_group}.csv'\n",
    "    A = pd.read_csv(adj_path, sep=' ', header=None).values\n",
    "    # Apply threshold: keep only edges with OR >= threshold\n",
    "    A_thresholded = (A >= or_threshold).astype(float)\n",
    "    return A_thresholded\n",
    "\n",
    "def compute_degree_outliers(gender: str, age_group: int, icd_df: pd.DataFrame, \n",
    "                            prev_dict: dict, or_threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"Compute high-degree outliers (80th percentile of log(degree/prevalence))\"\"\"\n",
    "    A = load_adjacency_matrix(gender, age_group, or_threshold)\n",
    "    G = nx.from_numpy_array(A)\n",
    "    \n",
    "    nodes = []\n",
    "    for node in range(len(A)):\n",
    "        degree = G.degree(node)\n",
    "        if degree > 0:\n",
    "            icd_row = icd_df[icd_df['diagnose_id'] == node + 1]\n",
    "            if len(icd_row) > 0:\n",
    "                icd_code = icd_row.iloc[0]['icd_code']\n",
    "                prev = prev_dict.get(icd_code, 0)\n",
    "                if prev > 0:\n",
    "                    ratio = degree / prev\n",
    "                    log_ratio = np.log10(ratio)\n",
    "                    nodes.append({\n",
    "                        'node': node, 'icd_code': icd_code,\n",
    "                        'degree': degree, 'prevalence': prev,\n",
    "                        'log_ratio': log_ratio\n",
    "                    })\n",
    "    \n",
    "    df_nodes = pd.DataFrame(nodes)\n",
    "    if len(df_nodes) > 0:\n",
    "        upper_bound = df_nodes['log_ratio'].quantile(0.80)\n",
    "        outliers = df_nodes[df_nodes['log_ratio'] >= upper_bound].copy()\n",
    "        outliers['Sex'] = gender\n",
    "        outliers['Age_Group'] = age_group\n",
    "        outliers['OR_Threshold'] = or_threshold\n",
    "        return outliers\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def compute_high_mortality_sinks(gender: str, age_group: int, icd_df: pd.DataFrame,\n",
    "                                mort_dict: dict, or_threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"Compute high-mortality sinks (top 20% Z-score product)\"\"\"\n",
    "    A = load_adjacency_matrix(gender, age_group, or_threshold)\n",
    "    G = nx.from_numpy_array(A)\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    \n",
    "    nodes = []\n",
    "    for node in range(len(A)):\n",
    "        bet = betweenness.get(node, 0)\n",
    "        if bet > 0:\n",
    "            icd_row = icd_df[icd_df['diagnose_id'] == node + 1]\n",
    "            if len(icd_row) > 0:\n",
    "                icd_code = icd_row.iloc[0]['icd_code']\n",
    "                mort = mort_dict.get(icd_code, 0)\n",
    "                nodes.append({\n",
    "                    'node': node, 'icd_code': icd_code,\n",
    "                    'betweenness': bet, 'mortality': mort\n",
    "                })\n",
    "    \n",
    "    df_nodes = pd.DataFrame(nodes)\n",
    "    if len(df_nodes) > 0:\n",
    "        mean_bet, std_bet = df_nodes['betweenness'].mean(), df_nodes['betweenness'].std()\n",
    "        mean_mort, std_mort = df_nodes['mortality'].mean(), df_nodes['mortality'].std()\n",
    "        \n",
    "        if std_bet > 0 and std_mort > 0:\n",
    "            df_nodes['z_betweenness'] = (df_nodes['betweenness'] - mean_bet) / std_bet\n",
    "            df_nodes['z_mortality'] = (df_nodes['mortality'] - mean_mort) / std_mort\n",
    "            df_nodes['z_product'] = df_nodes['z_betweenness'] * df_nodes['z_mortality']\n",
    "            \n",
    "            threshold = df_nodes['z_product'].quantile(0.80)\n",
    "            sinks = df_nodes[df_nodes['z_product'] >= threshold].copy()\n",
    "            sinks['Sex'] = gender\n",
    "            sinks['Age_Group'] = age_group\n",
    "            sinks['OR_Threshold'] = or_threshold\n",
    "            return sinks\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def compute_high_mortality_bridges(gender: str, age_group: int, icd_df: pd.DataFrame,\n",
    "                                  mort_dict: dict, or_threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"Compute high-mortality bridges (top 5% Z-score, 30% mortality diff)\"\"\"\n",
    "    A = load_adjacency_matrix(gender, age_group, or_threshold)\n",
    "    G = nx.from_numpy_array(A)\n",
    "    edge_betweenness = nx.edge_betweenness_centrality(G)\n",
    "    \n",
    "    edges = []\n",
    "    for (node1, node2), bet in edge_betweenness.items():\n",
    "        if bet > 0:\n",
    "            icd_row1 = icd_df[icd_df['diagnose_id'] == node1 + 1]\n",
    "            icd_row2 = icd_df[icd_df['diagnose_id'] == node2 + 1]\n",
    "            \n",
    "            if len(icd_row1) > 0 and len(icd_row2) > 0:\n",
    "                icd1 = icd_row1.iloc[0]['icd_code']\n",
    "                icd2 = icd_row2.iloc[0]['icd_code']\n",
    "                mort1 = mort_dict.get(icd1, 0)\n",
    "                mort2 = mort_dict.get(icd2, 0)\n",
    "                mort_diff = abs(mort1 - mort2)\n",
    "                \n",
    "                edges.append({\n",
    "                    'node1': node1, 'node2': node2,\n",
    "                    'icd1': icd1, 'icd2': icd2,\n",
    "                    'betweenness': bet,\n",
    "                    'mortality1': mort1, 'mortality2': mort2,\n",
    "                    'mort_diff': mort_diff\n",
    "                })\n",
    "    \n",
    "    df_edges = pd.DataFrame(edges)\n",
    "    if len(df_edges) > 0:\n",
    "        # Filter by 10% mortality difference (as in original Z-score method)\n",
    "        df_edges = df_edges[df_edges['mort_diff'] >= 0.10].copy()\n",
    "        \n",
    "        if len(df_edges) > 0:\n",
    "            mean_bet, std_bet = df_edges['betweenness'].mean(), df_edges['betweenness'].std()\n",
    "            mean_diff, std_diff = df_edges['mort_diff'].mean(), df_edges['mort_diff'].std()\n",
    "            \n",
    "            if std_bet > 0 and std_diff > 0:\n",
    "                df_edges['z_betweenness'] = (df_edges['betweenness'] - mean_bet) / std_bet\n",
    "                df_edges['z_mort_diff'] = (df_edges['mort_diff'] - mean_diff) / std_diff\n",
    "                df_edges['z_product'] = df_edges['z_betweenness'] * df_edges['z_mort_diff']\n",
    "                \n",
    "                threshold = df_edges['z_product'].quantile(0.95)\n",
    "                bridges = df_edges[df_edges['z_product'] >= threshold].copy()\n",
    "                bridges['Sex'] = gender\n",
    "                bridges['Age_Group'] = age_group\n",
    "                bridges['OR_Threshold'] = or_threshold\n",
    "                return bridges\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def create_unique_identifier(row, is_edge=False):\n",
    "    \"\"\"Create unique identifier for node or edge\"\"\"\n",
    "    if is_edge:\n",
    "        return f\"{row['Sex']}_{row['Age_Group']}_{row['icd1']}_{row['icd2']}\"\n",
    "    else:\n",
    "        return f\"{row['Sex']}_{row['Age_Group']}_{row['icd_code']}\"\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: RUN ANALYSIS FOR ALL THRESHOLDS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 2: Computing critical nodes/edges for each threshold...\")\n",
    "print()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for threshold_key, threshold_info in THRESHOLDS.items():\n",
    "    threshold_name = threshold_info['name']\n",
    "    threshold_value = threshold_info['value']\n",
    "    \n",
    "    print(f\"Processing: {threshold_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_outliers = []\n",
    "    all_sinks = []\n",
    "    all_bridges = []\n",
    "    \n",
    "    for gender in ['Female', 'Male']:\n",
    "        for age_group in available_age_groups[gender]:\n",
    "            age_str = AGE_MAP[age_group]\n",
    "            print(f\"  {gender} age {age_group} ({age_str})...\", end=' ')\n",
    "            \n",
    "            # Get prevalence and mortality\n",
    "            prev_subset = prev_df[\n",
    "                (prev_df['sex'] == gender) & \n",
    "                (prev_df['Age_Group'] == age_str) &\n",
    "                (prev_df['year'] == 2014)\n",
    "            ]\n",
    "            prev_dict = dict(zip(prev_subset['icd_code'], prev_subset['p']))\n",
    "            \n",
    "            mort_subset = mort_df[\n",
    "                (mort_df['sex'] == gender) &\n",
    "                (mort_df['Age_Group'] == age_str)\n",
    "            ]\n",
    "            mort_dict = dict(zip(mort_subset['icd_code'], mort_subset['mortality']))\n",
    "            \n",
    "            try:\n",
    "                # Compute metrics\n",
    "                outliers = compute_degree_outliers(gender, age_group, icd_df, prev_dict, threshold_value)\n",
    "                if len(outliers) > 0:\n",
    "                    all_outliers.append(outliers)\n",
    "                \n",
    "                sinks = compute_high_mortality_sinks(gender, age_group, icd_df, mort_dict, threshold_value)\n",
    "                if len(sinks) > 0:\n",
    "                    all_sinks.append(sinks)\n",
    "                \n",
    "                bridges = compute_high_mortality_bridges(gender, age_group, icd_df, mort_dict, threshold_value)\n",
    "                if len(bridges) > 0:\n",
    "                    all_bridges.append(bridges)\n",
    "                \n",
    "                print(\"✓\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "    \n",
    "    # Store results\n",
    "    results[threshold_key] = {\n",
    "        'name': threshold_name,\n",
    "        'value': threshold_value,\n",
    "        'outliers_df': pd.concat(all_outliers, ignore_index=True) if all_outliers else pd.DataFrame(),\n",
    "        'sinks_df': pd.concat(all_sinks, ignore_index=True) if all_sinks else pd.DataFrame(),\n",
    "        'bridges_df': pd.concat(all_bridges, ignore_index=True) if all_bridges else pd.DataFrame()\n",
    "    }\n",
    "    \n",
    "    # Create unique identifiers\n",
    "    if len(results[threshold_key]['outliers_df']) > 0:\n",
    "        results[threshold_key]['outliers_set'] = set(\n",
    "            results[threshold_key]['outliers_df'].apply(create_unique_identifier, axis=1)\n",
    "        )\n",
    "    else:\n",
    "        results[threshold_key]['outliers_set'] = set()\n",
    "    \n",
    "    if len(results[threshold_key]['sinks_df']) > 0:\n",
    "        results[threshold_key]['sinks_set'] = set(\n",
    "            results[threshold_key]['sinks_df'].apply(create_unique_identifier, axis=1)\n",
    "        )\n",
    "    else:\n",
    "        results[threshold_key]['sinks_set'] = set()\n",
    "    \n",
    "    if len(results[threshold_key]['bridges_df']) > 0:\n",
    "        results[threshold_key]['bridges_set'] = set(\n",
    "            results[threshold_key]['bridges_df'].apply(\n",
    "                lambda row: create_unique_identifier(row, is_edge=True), axis=1\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        results[threshold_key]['bridges_set'] = set()\n",
    "    \n",
    "    print(f\"  ✓ Outliers: {len(results[threshold_key]['outliers_set'])}\")\n",
    "    print(f\"  ✓ Sinks: {len(results[threshold_key]['sinks_set'])}\")\n",
    "    print(f\"  ✓ Bridges: {len(results[threshold_key]['bridges_set'])}\")\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: COMPUTE OVERLAP STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 3: Computing overlap statistics...\")\n",
    "print()\n",
    "\n",
    "def compute_jaccard(set1, set2):\n",
    "    \"\"\"Compute Jaccard index\"\"\"\n",
    "    if len(set1) == 0 and len(set2) == 0:\n",
    "        return np.nan\n",
    "    union = set1 | set2\n",
    "    if len(union) == 0:\n",
    "        return 0.0\n",
    "    intersection = set1 & set2\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "comparisons = [\n",
    "    ('or_1.5', 'or_2.0', 'OR > 1.5 vs OR > 2.0')\n",
    "]\n",
    "\n",
    "overlap_results = []\n",
    "\n",
    "for key1, key2, label in comparisons:\n",
    "    r1 = results[key1]\n",
    "    r2 = results[key2]\n",
    "    \n",
    "    stats = {\n",
    "        'comparison': label,\n",
    "        'condition1': r1['name'],\n",
    "        'condition2': r2['name'],\n",
    "        \n",
    "        'outliers_jaccard': compute_jaccard(r1['outliers_set'], r2['outliers_set']),\n",
    "        'outliers_common': len(r1['outliers_set'] & r2['outliers_set']),\n",
    "        'outliers_cond1_only': len(r1['outliers_set'] - r2['outliers_set']),\n",
    "        'outliers_cond2_only': len(r2['outliers_set'] - r1['outliers_set']),\n",
    "        \n",
    "        'sinks_jaccard': compute_jaccard(r1['sinks_set'], r2['sinks_set']),\n",
    "        'sinks_common': len(r1['sinks_set'] & r2['sinks_set']),\n",
    "        'sinks_cond1_only': len(r1['sinks_set'] - r2['sinks_set']),\n",
    "        'sinks_cond2_only': len(r2['sinks_set'] - r1['sinks_set']),\n",
    "        \n",
    "        'bridges_jaccard': compute_jaccard(r1['bridges_set'], r2['bridges_set']),\n",
    "        'bridges_common': len(r1['bridges_set'] & r2['bridges_set']),\n",
    "        'bridges_cond1_only': len(r1['bridges_set'] - r2['bridges_set']),\n",
    "        'bridges_cond2_only': len(r2['bridges_set'] - r1['bridges_set'])\n",
    "    }\n",
    "    \n",
    "    overlap_results.append(stats)\n",
    "    \n",
    "    print(f\"{label}:\")\n",
    "    print(f\"  Outliers: J={stats['outliers_jaccard']:.3f}, Common={stats['outliers_common']}\")\n",
    "    print(f\"  Sinks:    J={stats['sinks_jaccard']:.3f}, Common={stats['sinks_common']}\")\n",
    "    print(f\"  Bridges:  J={stats['bridges_jaccard']:.3f}, Common={stats['bridges_common']}\")\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 4: Saving results...\")\n",
    "print()\n",
    "\n",
    "# Summary table\n",
    "summary_data = []\n",
    "for key, data in results.items():\n",
    "    summary_data.append({\n",
    "        'Condition': data['name'],\n",
    "        'OR_Threshold': data['value'],\n",
    "        'Outliers': len(data['outliers_set']),\n",
    "        'Sinks': len(data['sinks_set']),\n",
    "        'Bridges': len(data['bridges_set'])\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv(OUTPUT_DIR / 'threshold_robustness_summary.csv', index=False)\n",
    "print(f\"  ✓ Saved: threshold_robustness_summary.csv\")\n",
    "\n",
    "# Overlap statistics\n",
    "overlap_df = pd.DataFrame(overlap_results)\n",
    "overlap_df.to_csv(OUTPUT_DIR / 'threshold_robustness_overlap_statistics.csv', index=False)\n",
    "print(f\"  ✓ Saved: threshold_robustness_overlap_statistics.csv\")\n",
    "\n",
    "# Detailed results for each condition\n",
    "for key, data in results.items():\n",
    "    if len(data['outliers_df']) > 0:\n",
    "        data['outliers_df'].to_csv(OUTPUT_DIR / f'threshold_{key}_outliers.csv', index=False)\n",
    "        print(f\"  ✓ Saved: threshold_{key}_outliers.csv\")\n",
    "    \n",
    "    if len(data['sinks_df']) > 0:\n",
    "        data['sinks_df'].to_csv(OUTPUT_DIR / f'threshold_{key}_sinks.csv', index=False)\n",
    "        print(f\"  ✓ Saved: threshold_{key}_sinks.csv\")\n",
    "    \n",
    "    if len(data['bridges_df']) > 0:\n",
    "        data['bridges_df'].to_csv(OUTPUT_DIR / f'threshold_{key}_bridges.csv', index=False)\n",
    "        print(f\"  ✓ Saved: threshold_{key}_bridges.csv\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: CREATE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 5: Creating visualizations...\")\n",
    "print()\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# FIGURE 1: Comparison Bars\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics = ['Outliers', 'Sinks', 'Bridges']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    thresholds = summary_df['OR_Threshold'].values\n",
    "    values = summary_df[metric].values\n",
    "    \n",
    "    bars = ax.bar(range(len(thresholds)), values, color=colors[idx], \n",
    "                  alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_xticks(range(len(thresholds)))\n",
    "    ax.set_xticklabels(['OR > 1.5\\n(Baseline)', 'OR > 2.0\\n(Strict)'], fontsize=11)\n",
    "    ax.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{metric}', fontsize=13, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{int(val)}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Counts of Critical Nodes/Edges Across OR Thresholds',\n",
    "             fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'threshold_comparison_bars.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved: threshold_comparison_bars.png\")\n",
    "plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# FIGURE 2: Jaccard Indices\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "comparisons_labels = overlap_df['comparison'].values\n",
    "metrics_lower = ['outliers', 'sinks', 'bridges']\n",
    "metric_names = ['Outliers', 'Sinks', 'Bridges']\n",
    "\n",
    "x = np.arange(len(metric_names))\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "# Since we only have one comparison, create a simple bar chart\n",
    "values = [overlap_df.loc[0, f'{m}_jaccard'] for m in metrics_lower]\n",
    "\n",
    "bars = ax.bar(x, values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "for bar, val in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    if not np.isnan(val):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "               f'{val:.3f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Metric', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Jaccard Index', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Robustness: OR > 1.5 vs OR > 2.0',\n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metric_names, fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "ax.axhline(y=0.7, color='green', linestyle='--', alpha=0.6, linewidth=2, label='J > 0.70')\n",
    "ax.axhline(y=0.4, color='orange', linestyle='--', alpha=0.6, linewidth=2, label='J > 0.40')\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "ax.legend(loc='lower left', framealpha=0.95, fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'threshold_jaccard_indices.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved: threshold_jaccard_indices.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Calculate average Jaccard indices from overlap statistics\n",
    "avg_outliers = overlap_df['outliers_jaccard'].mean()\n",
    "avg_sinks = overlap_df['sinks_jaccard'].mean()\n",
    "avg_bridges = overlap_df['bridges_jaccard'].mean()\n",
    "overall_avg = np.mean([avg_outliers, avg_sinks, avg_bridges])\n",
    "\n",
    "if overall_avg > 0.7:\n",
    "    assessment = \"EXCELLENT\"\n",
    "elif overall_avg > 0.5:\n",
    "    assessment = \"GOOD\"\n",
    "else:\n",
    "    assessment = \"MODERATE\"\n",
    "\n",
    "print(f\"Average Jaccard Indices:\")\n",
    "print(f\"  Outliers: {avg_outliers:.3f}\")\n",
    "print(f\"  Sinks:    {avg_sinks:.3f}\")\n",
    "print(f\"  Bridges:  {avg_bridges:.3f}\")\n",
    "print(f\"  Overall:  {overall_avg:.3f} - {assessment}\")\n",
    "print()\n",
    "print(\"Output files:\")\n",
    "print(f\"  CSV files: {OUTPUT_DIR}/threshold_*.csv\")\n",
    "print(f\"  Figures:   {FIG_DIR}/*.png\")\n",
    "print()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22f496d8-e9d7-4f29-8f48-aa8316c74604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EDGE WEIGHT DISTRIBUTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading critical disease identifications...\n",
      "  ✓ Outliers: 785\n",
      "  ✓ Sinks: 432\n",
      "  ✓ Bridges: 115\n",
      "\n",
      "Step 2: Extracting edge weights...\n",
      "  Processing outliers...\n",
      "    Collected 31534 edge weights\n",
      "  Processing sinks...\n",
      "    Collected 11728 edge weights\n",
      "  Processing bridges...\n",
      "    Collected 115 edge weights\n",
      "\n",
      "Step 3: Creating visualizations...\n",
      "  ✓ Saved: edge_weight_histograms_separate.png\n",
      "  ✓ Saved: edge_weight_histograms_overlaid.png\n",
      "  ✓ Saved: edge_weight_boxplots.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Outliers (edges connected to high-degree outliers):\n",
      "  Count:   31534\n",
      "  Mean:    8.865\n",
      "  Median:  3.106\n",
      "  Std:     34.319\n",
      "  Min:     1.500\n",
      "  Max:     1238.994\n",
      "  Q25:     2.192\n",
      "  Q75:     5.566\n",
      "\n",
      "Sinks (edges connected to high-mortality sinks):\n",
      "  Count:   11728\n",
      "  Mean:    9.404\n",
      "  Median:  3.398\n",
      "  Std:     19.856\n",
      "  Min:     1.502\n",
      "  Max:     341.887\n",
      "  Q25:     2.162\n",
      "  Q75:     7.643\n",
      "\n",
      "Bridges (high-mortality bridge edges):\n",
      "  Count:   115\n",
      "  Mean:    9.537\n",
      "  Median:  2.724\n",
      "  Std:     24.142\n",
      "  Min:     1.510\n",
      "  Max:     227.908\n",
      "  Q25:     2.045\n",
      "  Q75:     6.758\n",
      "\n",
      "✓ Saved statistics to: edge_weight_statistics.csv\n",
      "\n",
      "================================================================================\n",
      "✓ ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Output files:\n",
      "  Figures:    outputs/edge_weight_histograms/*.png\n",
      "  Statistics: outputs/edge_weight_statistics.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Edge Weight Distribution Analysis for Critical Diseases\n",
    "=======================================================\n",
    "Generates histograms showing the distribution of edge weights (odds ratios)\n",
    "for edges connected to outliers, sinks, and bridges in the OR > 1.5 network.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path('Data')\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "FIG_DIR = OUTPUT_DIR / 'edge_weight_histograms'\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Age group mapping\n",
    "AGE_MAP = {1: '0-9', 2: '10-19', 3: '20-29', 4: '30-39',\n",
    "           5: '40-49', 6: '50-59', 7: '60-69', 8: '70-79'}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EDGE WEIGHT DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD CRITICAL DISEASE LISTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 1: Loading critical disease identifications...\")\n",
    "\n",
    "# Load the OR > 1.5 results\n",
    "outliers_df = pd.read_csv(OUTPUT_DIR / 'threshold_or_1.5_outliers.csv')\n",
    "sinks_df = pd.read_csv(OUTPUT_DIR / 'threshold_or_1.5_sinks.csv')\n",
    "bridges_df = pd.read_csv(OUTPUT_DIR / 'threshold_or_1.5_bridges.csv')\n",
    "\n",
    "print(f\"  ✓ Outliers: {len(outliers_df)}\")\n",
    "print(f\"  ✓ Sinks: {len(sinks_df)}\")\n",
    "print(f\"  ✓ Bridges: {len(bridges_df)}\")\n",
    "print()\n",
    "\n",
    "# Load ICD mapping\n",
    "icd_df = pd.read_csv(DATA_DIR / 'ICD10_Diagnoses_All.csv')\n",
    "icd_to_node = dict(zip(icd_df['icd_code'], icd_df['diagnose_id'] - 1))  # 0-indexed\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: EXTRACT EDGE WEIGHTS FOR EACH CATEGORY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 2: Extracting edge weights...\")\n",
    "\n",
    "def get_edge_weights_for_nodes(icd_codes, sex, age_group):\n",
    "    \"\"\"Get all edge weights for given nodes (outliers or sinks)\"\"\"\n",
    "    # Load adjacency matrix\n",
    "    adj_path = DATA_DIR / f'Adj_Matrix_{sex}_ICD_age_{age_group}.csv'\n",
    "    if not adj_path.exists():\n",
    "        return []\n",
    "    \n",
    "    A = pd.read_csv(adj_path, sep=' ', header=None).values\n",
    "    \n",
    "    weights = []\n",
    "    for icd_code in icd_codes:\n",
    "        node = icd_to_node.get(icd_code)\n",
    "        if node is None:\n",
    "            continue\n",
    "        \n",
    "        # Get all edges connected to this node\n",
    "        # Outgoing edges\n",
    "        for neighbor in range(len(A)):\n",
    "            if neighbor != node and A[node, neighbor] >= 1.5:\n",
    "                weights.append(A[node, neighbor])\n",
    "        \n",
    "        # Incoming edges (if matrix is not symmetric)\n",
    "        for neighbor in range(len(A)):\n",
    "            if neighbor != node and A[neighbor, node] >= 1.5:\n",
    "                weights.append(A[neighbor, node])\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def get_edge_weights_for_bridges(bridges_subset):\n",
    "    \"\"\"Get edge weights for specific bridge edges\"\"\"\n",
    "    weights = []\n",
    "    \n",
    "    for _, row in bridges_subset.iterrows():\n",
    "        sex = row['Sex']\n",
    "        age_group = row['Age_Group']\n",
    "        icd1 = row['icd1']\n",
    "        icd2 = row['icd2']\n",
    "        \n",
    "        # Load adjacency matrix\n",
    "        adj_path = DATA_DIR / f'Adj_Matrix_{sex}_ICD_age_{age_group}.csv'\n",
    "        if not adj_path.exists():\n",
    "            continue\n",
    "        \n",
    "        A = pd.read_csv(adj_path, sep=' ', header=None).values\n",
    "        \n",
    "        node1 = icd_to_node.get(icd1)\n",
    "        node2 = icd_to_node.get(icd2)\n",
    "        \n",
    "        if node1 is not None and node2 is not None:\n",
    "            weight = A[node1, node2]\n",
    "            if weight >= 1.5:\n",
    "                weights.append(weight)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Collect edge weights for each category\n",
    "outlier_weights = []\n",
    "sink_weights = []\n",
    "bridge_weights = []\n",
    "\n",
    "# Process outliers\n",
    "print(\"  Processing outliers...\")\n",
    "for sex in ['Female', 'Male']:\n",
    "    for age_group in range(1, 9):\n",
    "        subset = outliers_df[(outliers_df['Sex'] == sex) & (outliers_df['Age_Group'] == age_group)]\n",
    "        if len(subset) > 0:\n",
    "            icd_codes = subset['icd_code'].unique()\n",
    "            weights = get_edge_weights_for_nodes(icd_codes, sex, age_group)\n",
    "            outlier_weights.extend(weights)\n",
    "\n",
    "print(f\"    Collected {len(outlier_weights)} edge weights\")\n",
    "\n",
    "# Process sinks\n",
    "print(\"  Processing sinks...\")\n",
    "for sex in ['Female', 'Male']:\n",
    "    for age_group in range(1, 9):\n",
    "        subset = sinks_df[(sinks_df['Sex'] == sex) & (sinks_df['Age_Group'] == age_group)]\n",
    "        if len(subset) > 0:\n",
    "            icd_codes = subset['icd_code'].unique()\n",
    "            weights = get_edge_weights_for_nodes(icd_codes, sex, age_group)\n",
    "            sink_weights.extend(weights)\n",
    "\n",
    "print(f\"    Collected {len(sink_weights)} edge weights\")\n",
    "\n",
    "# Process bridges (these are specific edges, not nodes)\n",
    "print(\"  Processing bridges...\")\n",
    "bridge_weights = get_edge_weights_for_bridges(bridges_df)\n",
    "print(f\"    Collected {len(bridge_weights)} edge weights\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: CREATE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 3: Creating visualizations...\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# FIGURE 1: Three separate histograms\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "categories = [\n",
    "    ('Outliers', outlier_weights, '#3498db'),\n",
    "    ('Sinks', sink_weights, '#e74c3c'),\n",
    "    ('Bridges', bridge_weights, '#2ecc71')\n",
    "]\n",
    "\n",
    "for idx, (name, weights, color) in enumerate(categories):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    if len(weights) > 0:\n",
    "        # Create histogram with log-spaced bins\n",
    "        log_bins = np.logspace(np.log10(1.5), np.log10(max(weights)), 50)\n",
    "        counts, bins, patches = ax.hist(weights, bins=log_bins, color=color, alpha=0.7, \n",
    "                                        edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        # Set log scale and x-axis limits\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim(1.5, max(weights) * 1.1)\n",
    "        \n",
    "        # Add statistics\n",
    "        mean_weight = np.mean(weights)\n",
    "        median_weight = np.median(weights)\n",
    "        \n",
    "        ax.axvline(mean_weight, color='red', linestyle='--', linewidth=2, \n",
    "                  label=f'Mean: {mean_weight:.2f}')\n",
    "        ax.axvline(median_weight, color='orange', linestyle='--', linewidth=2,\n",
    "                  label=f'Median: {median_weight:.2f}')\n",
    "        \n",
    "        ax.set_xlabel('Odds Ratio (log scale)', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'{name}\\n(n={len(weights)} edges)', fontsize=13, fontweight='bold')\n",
    "        ax.legend(loc='upper left', fontsize=10)\n",
    "        ax.grid(axis='both', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add text with statistics\n",
    "        stats_text = f'Min: {np.min(weights):.2f}\\nMax: {np.max(weights):.2f}\\nStd: {np.std(weights):.2f}'\n",
    "        ax.text(0.98, 0.65, stats_text, transform=ax.transAxes,\n",
    "               fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No data', transform=ax.transAxes,\n",
    "               ha='center', va='center', fontsize=14)\n",
    "        ax.set_xlabel('Odds Ratio', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'{name}', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Distribution of Edge Weights (Odds Ratios > 1.5)',\n",
    "             fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'edge_weight_histograms_separate.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved: edge_weight_histograms_separate.png\")\n",
    "plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# FIGURE 2: Overlaid histograms\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Determine overall range for consistent bins\n",
    "all_weights = []\n",
    "if len(outlier_weights) > 0:\n",
    "    all_weights.extend(outlier_weights)\n",
    "if len(sink_weights) > 0:\n",
    "    all_weights.extend(sink_weights)\n",
    "if len(bridge_weights) > 0:\n",
    "    all_weights.extend(bridge_weights)\n",
    "\n",
    "if len(all_weights) > 0:\n",
    "    log_bins = np.logspace(np.log10(1.5), np.log10(max(all_weights)), 50)\n",
    "else:\n",
    "    log_bins = 50\n",
    "\n",
    "if len(outlier_weights) > 0:\n",
    "    ax.hist(outlier_weights, bins=log_bins, color='#3498db', alpha=0.5, \n",
    "           label=f'Outliers (n={len(outlier_weights)})', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "if len(sink_weights) > 0:\n",
    "    ax.hist(sink_weights, bins=log_bins, color='#e74c3c', alpha=0.5,\n",
    "           label=f'Sinks (n={len(sink_weights)})', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "if len(bridge_weights) > 0:\n",
    "    ax.hist(bridge_weights, bins=log_bins, color='#2ecc71', alpha=0.5,\n",
    "           label=f'Bridges (n={len(bridge_weights)})', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "if len(all_weights) > 0:\n",
    "    ax.set_xlim(1.5, max(all_weights) * 1.1)\n",
    "ax.set_xlabel('Odds Ratio (log scale)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Comparison of Edge Weight Distributions (OR > 1.5)',\n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper left', fontsize=11, framealpha=0.9)\n",
    "ax.grid(axis='both', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'edge_weight_histograms_overlaid.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved: edge_weight_histograms_overlaid.png\")\n",
    "plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# FIGURE 3: Box plots for comparison\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "data_to_plot = []\n",
    "labels = []\n",
    "\n",
    "if len(outlier_weights) > 0:\n",
    "    data_to_plot.append(outlier_weights)\n",
    "    labels.append(f'Outliers\\n(n={len(outlier_weights)})')\n",
    "\n",
    "if len(sink_weights) > 0:\n",
    "    data_to_plot.append(sink_weights)\n",
    "    labels.append(f'Sinks\\n(n={len(sink_weights)})')\n",
    "\n",
    "if len(bridge_weights) > 0:\n",
    "    data_to_plot.append(bridge_weights)\n",
    "    labels.append(f'Bridges\\n(n={len(bridge_weights)})')\n",
    "\n",
    "bp = ax.boxplot(data_to_plot, labels=labels, patch_artist=True,\n",
    "                medianprops=dict(color='red', linewidth=2),\n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                whiskerprops=dict(linewidth=1.5),\n",
    "                capprops=dict(linewidth=1.5))\n",
    "\n",
    "# Color boxes differently\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "# Set y-axis limits to start at 1.5\n",
    "if len(data_to_plot) > 0:\n",
    "    max_val = max([max(d) for d in data_to_plot])\n",
    "    ax.set_ylim(1.5, max_val * 1.2)\n",
    "ax.set_ylabel('Odds Ratio (log scale)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Distribution Comparison of Edge Weights (OR > 1.5)',\n",
    "             fontsize=15, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'edge_weight_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "print(\"  ✓ Saved: edge_weight_boxplots.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "def print_stats(name, weights):\n",
    "    if len(weights) > 0:\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Count:   {len(weights)}\")\n",
    "        print(f\"  Mean:    {np.mean(weights):.3f}\")\n",
    "        print(f\"  Median:  {np.median(weights):.3f}\")\n",
    "        print(f\"  Std:     {np.std(weights):.3f}\")\n",
    "        print(f\"  Min:     {np.min(weights):.3f}\")\n",
    "        print(f\"  Max:     {np.max(weights):.3f}\")\n",
    "        print(f\"  Q25:     {np.percentile(weights, 25):.3f}\")\n",
    "        print(f\"  Q75:     {np.percentile(weights, 75):.3f}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{name}: No data\")\n",
    "        print()\n",
    "\n",
    "print_stats(\"Outliers (edges connected to high-degree outliers)\", outlier_weights)\n",
    "print_stats(\"Sinks (edges connected to high-mortality sinks)\", sink_weights)\n",
    "print_stats(\"Bridges (high-mortality bridge edges)\", bridge_weights)\n",
    "\n",
    "# Save statistics to CSV\n",
    "stats_data = []\n",
    "for name, weights in [('Outliers', outlier_weights), ('Sinks', sink_weights), ('Bridges', bridge_weights)]:\n",
    "    if len(weights) > 0:\n",
    "        stats_data.append({\n",
    "            'Category': name,\n",
    "            'Count': len(weights),\n",
    "            'Mean': np.mean(weights),\n",
    "            'Median': np.median(weights),\n",
    "            'Std': np.std(weights),\n",
    "            'Min': np.min(weights),\n",
    "            'Max': np.max(weights),\n",
    "            'Q25': np.percentile(weights, 25),\n",
    "            'Q75': np.percentile(weights, 75)\n",
    "        })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "stats_df.to_csv(OUTPUT_DIR / 'edge_weight_statistics.csv', index=False)\n",
    "print(\"✓ Saved statistics to: edge_weight_statistics.csv\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Output files:\")\n",
    "print(f\"  Figures:    {FIG_DIR}/*.png\")\n",
    "print(f\"  Statistics: {OUTPUT_DIR}/edge_weight_statistics.csv\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db210360-262f-48c8-9383-bf6545672062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
